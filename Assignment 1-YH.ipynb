{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编程实践部分\n",
    "#1. 设计你自己的句子生成器\n",
    "#1.1.定义自己的语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语法一：甲方催图\n",
    "owner = '''\n",
    "owner = 量词 项目 原因 ， 时间 要求 \n",
    "量词 = 这张 | 这套 \n",
    "项目 = 图 | 规范书 | 图纸\n",
    "原因 = 很急 | 全都不对 | 有问题\n",
    "时间 = 今天下班前 | 今天加班 |一个小时后\n",
    "要求 = 完成 | 改完 | 交给我\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#语法二：旅游网客服\n",
    "agent = '''\n",
    "agent = 寒暄 报数 询问 具体业务 结尾\n",
    "寒暄 = 称谓 您好 | 您好\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 \n",
    "报数 = 我是 数字 号客服 ,\n",
    "数字 = 单个数字 | 数字 单个数字\n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "询问 = 请问您要 | 您需要\n",
    "具体业务 = 具体业务1 | 具体业务2\n",
    "具体业务1 = 订机票 | 订酒店 | 定制旅游\n",
    "具体业务2 = 投诉 | 提建议 | 人工服务 | 兑现奖品\n",
    "结尾 = 吗？'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把语法存储在一个字典里\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成句子模型\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target # means target is a terminal expression\n",
    "    \n",
    "    expanded = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expanded if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您好我是8号客服,请问您要投诉吗？'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2 用generate函数生成随机句子\n",
    "generate(gram=create_grammar(agent), target='agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:\n",
    "def generate_n(gram,target,n):\n",
    "    sens=[]\n",
    "    for i in range(n):\n",
    "        sens.append(generate(gram,target)) \n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['您好我是42号客服,请问您要订酒店吗？',\n",
       " '您好我是417号客服,您需要提建议吗？',\n",
       " '您好我是4号客服,请问您要订酒店吗？',\n",
       " '您好我是3号客服,您需要提建议吗？',\n",
       " '女士,您好我是74号客服,请问您要定制旅游吗？']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(gram=create_grammar(agent), target='agent',n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 使用新数据源完成语言模型的训练\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\yuan-he\\Desktop\\【袁禾-人工智能与自然语言处理】培训课程编程能力测试及课程协议\\第一课\\Assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 获取文本数据集\n",
    "data = pd.read_csv('movie_comments.csv', encoding='utf-8',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=data['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据清洗\n",
    "def token(string):\n",
    "    # we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步看了恶心想吐',\n",
       " '首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬2刻意做作的主旋律煽情显得如此不合时宜而又多余',\n",
       " '凭良心说好看到不像战狼1的续集完虐湄公河行动',\n",
       " '中二得很']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#进行文本清洗，获得所有的纯文本\n",
    "comment_clean = [''.join(token(str(a)))for a in comment]\n",
    "comment_clean[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('douban_comment.txt', 'w',encoding='utf-8') as f:\n",
    "    for a in comment_clean:\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n"
     ]
    }
   ],
   "source": [
    "#将这些文本进行切词\n",
    "TOKEN=[]\n",
    "for i, line in enumerate((open('douban_comment.txt',encoding='utf-8'))):   \n",
    "    if i % 20000 == 0: print(i)\n",
    "    TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328262),\n",
       " ('\\n', 261497),\n",
       " ('了', 102420),\n",
       " ('是', 73106),\n",
       " ('我', 50338),\n",
       " ('都', 36255),\n",
       " ('很', 34712),\n",
       " ('看', 34022),\n",
       " ('电影', 33675),\n",
       " ('也', 32065),\n",
       " ('和', 31290),\n",
       " ('在', 31245),\n",
       " ('不', 28435),\n",
       " ('有', 27939),\n",
       " ('就', 25685),\n",
       " ('人', 23909),\n",
       " ('好', 22858),\n",
       " ('啊', 20803),\n",
       " ('这', 17484),\n",
       " ('还', 17449),\n",
       " ('一个', 17343),\n",
       " ('你', 17282),\n",
       " ('还是', 16425),\n",
       " ('但', 15578),\n",
       " ('故事', 15010),\n",
       " ('没有', 14343),\n",
       " ('就是', 14007),\n",
       " ('喜欢', 13566),\n",
       " ('让', 13304),\n",
       " ('太', 12676),\n",
       " ('又', 11566),\n",
       " ('剧情', 11359),\n",
       " ('没', 10858),\n",
       " ('说', 10764),\n",
       " ('吧', 10747),\n",
       " ('他', 10675),\n",
       " ('不错', 10416),\n",
       " ('得', 10349),\n",
       " ('到', 10341),\n",
       " ('给', 10300),\n",
       " ('这个', 10058),\n",
       " ('上', 10054),\n",
       " ('被', 9939),\n",
       " ('对', 9824),\n",
       " ('最后', 9694),\n",
       " ('一部', 9693),\n",
       " ('片子', 9590),\n",
       " ('什么', 9571),\n",
       " ('能', 9532),\n",
       " ('与', 9168)]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = [str(t) for t in TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    if words_count[word]==0:\n",
    "        return 1 / len(TOKEN)/2 #出现次数为0的单词。设定概率为出现为1的一半\n",
    "    return words_count[word] / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0202836478241545e-05"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011048426199038344"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('看', '电影')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 获得新的2-gram语言模型\n",
    "def get_probability(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)/prob_1(word)\n",
    "        #count(w1,w2)/count(w2)        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.22108378102271e-08"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天抽奖抽到一台飞机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天晚上请你吃大餐，我们一起吃苹果 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 5.589773310824115e-21\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 2.6830911891955763e-20\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 1.4840419116340077e-14\n",
      "---- 真是一只好看的小猫 with probility 1.5056754580120136e-12\n",
      "今晚我去吃火锅 is more possible\n",
      "---- 今晚我去吃火锅 with probility 1.739333221620318e-08\n",
      "---- 今晚火锅去吃我 with probility 3.784619239336749e-09\n",
      "养乐多绿来一杯 is more possible\n",
      "---- 洋葱奶昔来一杯 with probility 1.9778505986507345e-05\n",
      "---- 养乐多绿来一杯 with probility 2.000001683570061\n"
     ]
    }
   ],
   "source": [
    "comment_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "\n",
    "for s in comment_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = get_probability(s1), get_probability(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 获得最优质的的语言\n",
    "#生成n个句子，并能选择一个最合理的句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar,target,n): \n",
    "    sens=[]\n",
    "    for i in range(n):\n",
    "        sen=generate(create_grammar(grammar), target)\n",
    "        pro=get_probability(sen)\n",
    "        sens.append((sen,pro))\n",
    "    sorted_sens=sorted(sens,key=lambda x :x[1],reverse=True)\n",
    "    return sorted_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('您好我是53号客服,您需要订机票吗？', 1.5883836988955677e-20),\n",
       " ('您好我是8号客服,您需要人工服务吗？', 4.7989744460175026e-23),\n",
       " ('您好我是258号客服,您需要提建议吗？', 1.1177933620226865e-23),\n",
       " ('先生,您好我是18号客服,请问您要订机票吗？', 1.8977261203258143e-24),\n",
       " ('您好我是3号客服,请问您要提建议吗？', 1.6011221520948315e-25)]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(host,'host',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型有什么问题，你准备如何提升？\n",
    "Ans:这个模型不能生成复杂的句子，用来计算概率的数据不够全面，只是针对电影的评论，对于生活化、工作化的语言不能很好的预测，如吃饭吃苹果的句子没有预测正确\n",
    "提升：完善数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Can you come up out 3 sceneraies which use AI methods? <br>\n",
    "ans: 自动驾驶，客服机器人，百度识图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do we use Github; Why do we use Jupyter and Pycharm;<br>\n",
    "ans:用Github来存储不同版本的文件，方便团队协作完成项目 <br>\n",
    "用Jupyter比较方便记笔记，Pycharm可以写py文件，方便查看变量，适合于大型项目的开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What's the Probability Model? <br>\n",
    "ans:概率模型是用来描述不同随机变量之间关系的数学模型，<br>\n",
    "通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you came up with some sceneraies at which we could use Probability Model? <br>\n",
    "ans:自动答复，机器翻译，股票预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match? <br>\n",
    "ans:1.因为可以基于大量的数据的统计特性提高智能识别的正确性\n",
    "2.难点：如果要提升正确率，需要的数据量很大，运算慢\n",
    "递归的运算方式很慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.What's the Language Model? <br>\n",
    "ans: 计算句子出现概率的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Can you came up with some sceneraies at which we could use Language Model? <br>\n",
    "Ans: 机器翻译、语音识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.What's the 1-gram language model? <br>\n",
    "Ans: n-gram 语言模型的简化。一个句子(假设由四个词组成)出现的概率定义为$$ Pro(w_1 w_2 w_3 w_4) = Pr(w_1 | w_2 w_3 w_ 4) * P(w2 | w_3 w_4) * Pr(w_3 | w_4) * Pr(w_4)$$ <br>\n",
    "就是每个词出现的概率与它前面n-1个词出现的先验概率的乘积，如果句子太长，这个模型的计算量非常大，而且离这个词越远的单词实际上对概率的影响越来越小，所以可以进行简化，最简单的模式就是1-gram，概率就被简化为$$ Pro(w_1 w_2 w_3 w_4) \\sim Pr(w_1) * P(w_2) * Pr(w_3) * Pr(w_4)$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What's the disadvantages and advantages of 1-gram language model; <br>\n",
    "ans:优点是简单，缺点是准确度欠缺，损失了词语之间的关系信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What't the 2-gram models;\n",
    "ans:和1-gram一样，也是n-gram模型的简化，$$ Pro(w_1 w_2 w_3 w_4) \\sim Pr(w_1 | w_2 ) * P(w2 | w_3 ) * Pr(w_3 | w_4) * Pr(w_4)$$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
